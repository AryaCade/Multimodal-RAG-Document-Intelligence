import json
from typing import List
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langchain_core.documents import Document

from processing.content_analyzer import seperate_content_types
from config import SUMMARY_MODEL

def create_ai_enhanced_summary(text: str, tables: List[str], images: List[str]):
    """
    Creates an AI-enhanced summary of the provided text, tables, and images.
    
    Args:
        text: The main text content.
        tables: A list of HTML strings representing tables.
        images: A list of base64-encoded image strings.

    Returns:
        A comprehensive, searchable description generated by the AI.
    """

    llm = ChatGoogleGenerativeAI(model=SUMMARY_MODEL)

    prompt = f"""
    You are creating a searchable description for document retrieval.

    TEXT:
    {text}
    """
    
    # Add table if present
    if tables:
        prompt += "TABLES:\n"
        for i, table in enumerate(tables):
            print(f"Table {i+1}: \n{table}\n")

    prompt += """
                YOUR TASK:
                Generate a comprehensive, searchable description that covers:

                1. Key facts, numbers, and data points from text and tables
                2. Main topics and concepts discussed  
                3. Questions this content could answer
                4. Visual content analysis (charts, diagrams, patterns in images)
                5. Alternative search terms users might use

                Make it detailed and searchable - prioritize findability over brevity.

                SEARCHABLE DESCRIPTION:"""

    message_content = [{"type": "text", "text": prompt}]

    for image_base64 in images:
        message_content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
        })

    response = llm.invoke([HumanMessage(content=message_content)])
    return response.content


def summarise_chunks(chunks):
    documents = []

    for chunk in chunks:
        content = seperate_content_types(chunk)

        if content["tables"] or content["images"]:
            enhanced = create_ai_enhanced_summary(
                content["text"], content["tables"], content["images"]
            )
        else:
            enhanced = content["text"]

        documents.append(
            Document(
                page_content=enhanced,
                metadata={
                    "original_content": json.dumps({
                        "raw_text": content["text"],
                        "tables_html": content["tables"],
                        "images_base64": content["images"]
                    })
                }
            )
        )

    print(f"âœ… Processed {len(documents)} chunks")
    return documents
